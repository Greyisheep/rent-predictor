{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation and plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for saving the pipeline\n",
    "import joblib\n",
    "\n",
    "#for loading json file\n",
    "import json\n",
    "\n",
    "# from Scikit-learn\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import preprocessors as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting pandas to display all columns:\n",
    "pd.set_option('display.max_column', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config.json file\n",
    "\n",
    "with open('config.json') as config_file:\n",
    "    config = json.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data from the Google sheet directly:\n",
    "sheet_id = config['sheet_id']\n",
    "\n",
    "sheet_name = config['sheet_name']\n",
    "\n",
    "url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "#data = pd.read_csv('data.csv')\n",
    "\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# rows and columns of the data\n",
    "print(data.shape)\n",
    "\n",
    "# visualise the dataset\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers to the 'What utilities are available' question:\n",
    "\n",
    "['electricity', 'Refuse disposal', 'Constant running water in rooms', 'Security post', 'Cleaners', 'Lodge generator(for electricity)', 'Solar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the previous dataset 'data.csv'\n",
    "\n",
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempting to split the answers in the 'What utilities are availale?' section into columns that can be used for modelling\n",
    "\n",
    "all_utilities = set()\n",
    "for row in data['What utilities are available?']:\n",
    "    if isinstance(row, str):\n",
    "        utilities = [utility.strip() for utility in row.split(',')]\n",
    "        all_utilities.update(utilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_utilities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lodge generator and Lodge generator(for electricity) should hold the same information but from above would most likely be split into seperate columns, \n",
    "\n",
    "lets confirm if there are entries in the data that had these two occurrences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(data['What utilities are available?'].values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly there are, so this should be handled during data cleaning phase of the model building:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceeding with engineering columns for the answers to 'What Utilities are available'\n",
    "\n",
    "# Create columns for each utility and initialize with False\n",
    "for utility in all_utilities:\n",
    "    data[utility] = False\n",
    "\n",
    "# Update the columns based on the 'What utilities are available?' column\n",
    "for index, row in data.iterrows():\n",
    "    if pd.notna(row['What utilities are available?']):\n",
    "        utilities = [utility.strip() for utility in row['What utilities are available?'].split(',')]\n",
    "        for utility in utilities:\n",
    "            data.at[index, utility] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping that column since its entries has been made into columns\n",
    "data.drop('What utilities are available?',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('Timestamp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the resulting columns:\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns has now been split, The Model Building process can now resume for this engineered dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['Name', 'Rent', 'StrtName', 'Storeys', 'Cheaperflrs', 'LgCond', 'Age', 'GenHouse', 'Parking', 'Distance',\n",
    "       'Location', 'RdCond', 'SecurityLvl', 'RmSize', 'RmCond', 'Wdrobe',\n",
    "       'Finishing', 'Balcony', 'KitchenSize', 'BathrmSize', 'BalcnySize', \n",
    "       'RefDisposal', 'LodgeGen', 'SecPost', 'Solar', 'RunWater', 'Cleaners',\n",
    "       'Electricity', 'ElecLodgeGen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the \"rent\" column to numeric (ignore errors for non-numeric values)\n",
    "data['Rent'] = pd.to_numeric(data['Rent'], errors='coerce')\n",
    "\n",
    "# Apply the condition to the \"rent\" column using a mask\n",
    "mask = (data['Rent'].notna()) & (data['Rent'] < 1000)\n",
    "\n",
    "# Multiply the values that meet the condition by 1000\n",
    "data.loc[mask, 'Rent'] *= 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new 'Id' column with row IDs\n",
    "data['ID'] = range(1, len(data) + 1)\n",
    "\n",
    "# Reorder the columns so that 'ID' is the first column\n",
    "data = data[['ID'] + [col for col in data if col != 'ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each column to handle NaN values\n",
    "for col in data.columns:\n",
    "    if data[col].dtype in [int, float]:\n",
    "        # Replace NaN with the column's average\n",
    "        data[col].fillna(data[col].mean(), inplace=True)\n",
    "    elif data[col].dtype == 'object':\n",
    "        # Replace NaN with the most common string value in the same column\n",
    "        most_common = data[col].mode()[0]\n",
    "        data[col].fillna(most_common, inplace=True)\n",
    "    elif data[col].dtype == 'bool':\n",
    "        # Replace NaN with the most frequent boolean value\n",
    "        most_frequent = data[col].mode()[0]\n",
    "        data[col].fillna(most_frequent, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development:\n",
    "\n",
    "- Create a base model using the data retrieved from the URL directly after proper data cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's separate into train and test set\n",
    "# Remember to set the seed (random_state for this sklearn function)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(['ID', 'Rent'], axis=1), # predictive variables\n",
    "    data['Rent'], # target\n",
    "    test_size=0.3, # portion of dataset to allocate to test set\n",
    "    random_state=0, # we are setting the seed here\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical variables with NA in train set\n",
    "NUMERICAL_VARS_WITH_NA = ['KitchenSize', 'BathrmSize', 'BalcnySize']\n",
    "\n",
    "# variables to map\n",
    "SOME_VARS = ['Cheaperflrs', 'GenHouse', 'Parking', 'Wdrobe', 'Balcony']\n",
    "\n",
    "MORE_VARS = ['RefDisposal', 'LodgeGen', 'SecPost', 'Solar', 'RunWater', 'Cleaners',\n",
    "       'Electricity', 'ElecLodgeGen']\n",
    "\n",
    "# categorical variables to encode\n",
    "LOCATION_VARS = ['Location']\n",
    "\n",
    "FINISHING_VARS = ['Finishing']\n",
    "\n",
    "# variable mappings\n",
    "SOME_MAPPINGS = {'No':1, 'I don\\'t know':2,\n",
    "                 'Yes':3}\n",
    "\n",
    "MORE_MAPPINGS = {True:1, False:2}\n",
    "\n",
    "LOCATION_MAPPINGS = {'Near Eziobodo Gate':1, 'Near Sekani':2,\n",
    "                     'Around John Paul\\'s Kitchen':3, 'Dombolo':4,\n",
    "                     'Eziobodo Elu':5}\n",
    "\n",
    "FINISHING_MAPPINGS = {'Tiles':1, 'Cement':2}\n",
    "\n",
    "# the selected variables\n",
    "FEATURES = ['Storeys', 'Cheaperflrs', 'LgCond', 'Age', 'GenHouse', 'Parking', 'Distance',\n",
    "       'Location', 'RdCond', 'SecurityLvl', 'RmSize', 'RmCond', 'Wdrobe',\n",
    "       'Finishing', 'Balcony', 'KitchenSize', 'BathrmSize', 'BalcnySize', \n",
    "       'RefDisposal', 'LodgeGen', 'SecPost', 'Solar', 'RunWater', 'Cleaners',\n",
    "       'Electricity', 'ElecLodgeGen']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[FEATURES]\n",
    "X_test = X_test[FEATURES]\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_pipe = Pipeline([\n",
    "        # === mappers ===\n",
    "    ('mapper_SOME', pp.Mapper(\n",
    "        variables=SOME_VARS, mappings=SOME_MAPPINGS)),\n",
    "    \n",
    "    ('mapper_LOCATION', pp.Mapper(\n",
    "        variables=LOCATION_VARS, mappings=LOCATION_MAPPINGS)),\n",
    "    ('mapper_FINISHING', pp.Mapper(\n",
    "        variables=FINISHING_VARS, mappings=FINISHING_MAPPINGS)),\n",
    "    ('mapper_MORE', pp.Mapper(\n",
    "        variables=MORE_VARS, mappings=MORE_MAPPINGS)),\n",
    "        \n",
    "    ('scaler', MinMaxScaler()),\n",
    "#     ('selector', SelectFromModel(Lasso(alpha=0.001, random_state=0))),\n",
    "    ('Lasso', Lasso(alpha=0.044, random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the pipeline\n",
    "price_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model:\n",
    "# ====================\n",
    "\n",
    "# make predictions for train set\n",
    "pred = price_pipe.predict(X_train)\n",
    "\n",
    "# determine mse, rmse and r2\n",
    "print('train mse: {}'.format(int(\n",
    "    mean_squared_error(np.exp(y_train), np.exp(pred)))))\n",
    "print('train rmse: {}'.format(int(\n",
    "    mean_squared_error(np.exp(y_train), np.exp(pred), squared=False))))\n",
    "print('train r2: {}'.format(\n",
    "    r2_score(np.exp(y_train), np.exp(pred))))\n",
    "print()\n",
    "\n",
    "# make predictions for test set\n",
    "pred = price_pipe.predict(X_test)\n",
    "\n",
    "# determine mse, rmse and r2\n",
    "print('test mse: {}'.format(int(\n",
    "    mean_squared_error(np.exp(y_test), np.exp(pred)))))\n",
    "print('test rmse: {}'.format(int(\n",
    "    mean_squared_error(np.exp(y_test), np.exp(pred), squared=False))))\n",
    "print('test r2: {}'.format(\n",
    "    r2_score(np.exp(y_test), np.exp(pred))))\n",
    "print()\n",
    "\n",
    "print('Average lodge price: ', int(np.exp(y_train).median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's evaluate our predictions respect to the real sale price\n",
    "plt.scatter(y_test, price_pipe.predict(X_test))\n",
    "plt.xlabel('True Lodge Price')\n",
    "plt.ylabel('Predicted Lodge Price')\n",
    "plt.title('Evaluation of Lasso Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's evaluate the distribution of the errors: \n",
    "# they should be fairly normally distributed\n",
    "\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "preds = pd.Series(price_pipe.predict(X_test))\n",
    "\n",
    "errors = y_test - preds\n",
    "errors.hist(bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's save the scaler\n",
    "\n",
    "joblib.dump(price_pipe, 'price_pipe.joblib') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rent-pred-virtualenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "506c92340be7ed45fb29e4930ca5f628676b88956e3334d212789956ef4e3f95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
